---
title: "Homework 3: Probability, Statistics and Machine Learning"
subtitle: "Spring 2023 MATH/COSC 3570 Introduction to Data Science by Dr. Cheng-Han Yu"
format: 
  html:
    code-fold: false
    code-tools: true
date: "`r Sys.Date()`"
author: "**Noah Kaye**"
number-sections: true
from: markdown+emoji
editor: 
  source
---

```{r}
#| label: setup
#| include: false

####################################################
## !!!DO NOT MAKE ANY CHANGE OF THIS CODE CHUNK!!!##
####################################################

# Package names
packages <- c("knitr", "ggplot2", "ggrepel", 
              "tidyverse", "formatR", "dslabs", "janitor", 
              "ggthemes", "plotly", "tidymodels", "kknn")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
    install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```


- **Note: For any simulation or random sampling, set the random seed at your student ID number, for example `set.seed(6145678)`.**


# Probability and Statistics

## Monte Carlo Simulation

1. Milwaukee Bucks and Golden State Warriors are playing NBA Finals (I hope!). The first to win four games wins the series. The Bucks are a better team and have a 60% chance of winning each game. If the Bucks lose the first game, calculate the probability that they win the NBA championship? **[Hint]**: You can use binomial distribution, and given the first game loss, the probability $P(\text{Bucks wins the series})$ is

$$P(\text{Bucks wins 4 in a row}) + P(\text{Bucks wins 4 in 5 games}) + P(\text{Bucks wins 4 in 6 games})$$

```{r}

dbinom(x=4, size=4, prob=.6) + dbinom(x=3, size=4, prob=.6)*0.6 + dbinom(x=3, size=5, prob=.6)*0.6

```

2. Confirm the results of the previous question with a Monte Carlo simulation.

```{r}

## code
teams = c("bucks", "bucks", "bucks", "bucks", "warriors", "warriors", "warriors", "warriors")

set.seed(006220587)
mc4 <- replicate(10000, {
    #bucks_wins_4 <- sample(c(0, 1), 4, prob = c(0.4, 0.6), replace = TRUE)
    bucks_wins_4 <- rbinom(n = 1, size = 4, prob = 0.6)
    bucks_wins_4 == 4
})
mc4_result = mean(mc4)
mean(mc4)
0.6^4

mc5 <- replicate(10000, {
    bucks_wins_5 <- rbinom(n = 1, size = 4, prob = 0.6)
    bucks_wins_5 == 3
})
mc5_result = mean(mc5)*0.6
mc5_result
dbinom(x=3, size=4, prob=.6)*0.6

mc6 <- replicate(10000, {
    bucks_wins_6 <- rbinom(n = 1, size = 5, prob = 0.6)
    bucks_wins_6 == 3
})
mc6_result = mean(mc6)*0.6
mc6_result
dbinom(x=3, size=5, prob=0.6)*0.6

mc4_result + mc5_result + mc6_result

```


## Central Limit Theorem
Suppose random variables $X_1, X_2, \dots, X_n$ are independent and follow Chi-squared distribution with degrees of freedom 1, $\chi^2_{df=1}$.

1. Use `dchisq()` to plot $\chi^2_{df=1}$ distribution. Consider $x\in (0, 5)$.

```{r}

## code
df <- tibble(
  x = 0:5,
  y = dchisq(c(0:5), 1)
)

df |> ggplot(aes(x = x, y = y)) +
  geom_col()

```


2. Consider three sample sizes $n = 2, 8, 100$, and set the sample size of the sample mean $\overline{X}_n$ be $1000$. Show the sampling distribution of $\overline{X}_n$, i.e., the collection $\{\overline{X}_n^{(m)}\}_{m=1}^{1000}$, looks more and more like Gaussian as $n$ increases by making histograms of $\overline{X}_n$ samples with $n = 2, 8, 100$. The procedure is the following:

For each $n = 2, 8, 100$,

i. Draw $n$ values $x_1, x_2, \dots, x_n$ using `rchisq(n, df = 1)`.
ii. Compute the mean of the $n$ values, which is $\overline{x}_n$.
iii. Repeat i. and ii. 1000 times to obtain 1000 $\overline{x}_n$s.
iv. Plot the histogram of these 1000 $\overline{x}_n$s.


```{r}

## code
set.seed(006220587)

# 2
chi2 <- replicate(1000,
                  mean(rchisq(2, df = 1)))
chi2 |> hist()

#8
chi8 <- replicate(1000,
                  mean(rchisq(8, df = 1)))
chi8 |> hist()

#100
chi100 <- replicate(1000,
                    mean(rchisq(100, df = 1)))
chi100 |> hist()


```


# Machine Learning

## Linear Regression

A pharmaceutical firm would like to obtain information on the relationship between the dose level and potency of a drug product. To do this, each of 15 test tubes is inoculated with a virus culture and incubated for 5 days at 30°C. Three test tubes are randomly assigned to each of the five different dose levels to be investigated (2, 4, 8, 16, and 32 mg). Each tube is injected with only one dose level, and the response of interest is obtained.

1. Import `dose.csv` in the `/data` folder into your R session. The data set is not tidy. Use `pivot_longer()` to make it tidy as the shown tibble below. Call the tidy data set `dose_tidy`.

```{r}

## code
dose <- read_csv("./data/dose.csv", show_col_types = TRUE)
dose
dose_tidy <- dose |> pivot_longer(cols = tube_1:tube_3, 
                                  names_to = "tube", 
                                  values_to = "response"
                                  )
dose_tidy

## # A tibble: 15 × 3
##    dose_level tube  response
##         <dbl> <chr>    <dbl>
##  1          2 tube1        5
##  2          2 tube2        7
##  3          2 tube3        3
##  4          4 tube1       10
##  5          4 tube2       12
##  6          4 tube3       14
##  7          8 tube1       15
##  8          8 tube2       17
##  9          8 tube3       18
## 10         16 tube1       20
## 11         16 tube2       21
## 12         16 tube3       19
## 13         32 tube1       23
## 14         32 tube2       24
## 15         32 tube3       29
```


2. Fit a simple linear regression with the predictor $\texttt{dose level}$ for `response`. Print the fitted result. 

```{r}

## code
doseLin1 <- linear_reg() |> 
    set_engine("lm") |> 
    fit(response ~ dose_level, data = dose_tidy)
doseLin1

```

3. With (2), plot the data with a $95\%$ confidence interval for the mean response.

```{r}

## code
confLin <- as.tibble(predict(doseLin1$fit,
        interval = "prediction", 
        level = 0.95))

doseLin1$fit |> ggplot(aes(x = dose_level, y = response)) +
  geom_point() +
  geom_smooth(method = 'lm', se = TRUE, color = 'black') +
  geom_line(aes(x = dose_level, y = confLin$lwr),
            color = 'red') +
  geom_line(aes(x = dose_level, y = confLin$upr),
            color = 'red')

```

4. Fit a simple linear regression model with the predictor $\texttt{ln(dose level)}$ for `response`, where $\ln = \log_e$. Print the fitted result.

```{r}

## code
dose_tidy <- dose_tidy |> mutate(ln_dose_level = log(dose_level))

doseLin2 <- linear_reg() |>
    set_engine("lm") |>
    fit(response ~ ln_dose_level, data = dose_tidy)
doseLin2

```

5. With (4), plot the data $(\ln(\text{dose level})_i, y_i)$ with a $95\%$ confidence interval for the mean response.

```{r}
#|eval: false

## code
confLin <- as.tibble(predict(doseLin2$fit,
        interval = "prediction", 
        level = 0.95))

doseLin2$fit |> ggplot(aes(x = ln_dose_level, y = response)) +
  geom_point() +
  geom_smooth(method = 'lm', se = TRUE, color = 'black') +
  geom_line(aes(x = ln_dose_level, y = confLin$lwr),
            color = 'red') +
  geom_line(aes(x = ln_dose_level, y = confLin$upr),
            color = 'red')

```

6. Draw residual plots of Model in (2) and (4). According to the plots, which model you think is better?

```{r}

## code
plot(doseLin1$fit, which = 1, las = 1)
plot(doseLin2$fit, which = 1, las = 1)

```
There seems to be less of a pattern in the regression plot using ln_dose_level (the second one), whereas the first one seems to be overfitted, so the model used in the second regression plot is the better model.

7. Import `dose_tidy.csv` and redo (2) using **Python**. Show the slope and intercept.

```{python}

# code
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

dose_tidy = pd.read_csv('./data/dose_tidy.csv')
x = np.array(dose_tidy['dose_level']).reshape(-1, 1)
y = np.array(dose_tidy['response']).reshape(-1, 1)
reg = LinearRegression().fit(x, y)
reg.coef_
reg.intercept_

```



8. Use **Python** to predict the response value when the dose level is 10, 20, and 30.

```{python}

# code
new_input = np.arange(10, 20, 30).reshape(-1, 1)
pred = reg.predict(new_input)
pred

```


## Logistic Regression

1. Import `body.csv` in the `/data` folder. Split the data into a training set and a test set. Set the random seed at your student ID number. Use 80:20 rule.

```{r}

# code
  set.seed(006220587)
  body <- read_csv("./data/body.csv", show_col_types = TRUE)

df_split <- rsample::initial_split(
    data = body, 
    prop = 0.8)

df_trn <- rsample::training(df_split)
dim(df_trn)
df_tst <- rsample::testing(df_split)
dim(df_tst)

```

2. Fit a logistic regression with the predictor `HEIGHT` using the training sample data. Find the probability that the subject is male given `HEIGHT = 165`.

```{r}

# code
library(tidymodels)
logis_mdl_ht <- parsnip::logistic_reg() |> 
    set_engine("glm") 

df_trn$GENDER <- factor(df_trn$GENDER)

logis_fit_ht <- logis_mdl_ht |> 
    fit(GENDER ~ HEIGHT, 
        data = df_trn, 
        family = "binomial")

predict(logis_fit_ht$fit, newdata = data.frame(HEIGHT = 165), type = "response")

```

3. Fit a logistic regression with the predictor `BMI` using the training sample data. Find the probability that the subject is male given `BMI = 25`.

```{r}

# code
library(tidymodels)
logis_mdl_bmi <- parsnip::logistic_reg() |> 
    set_engine("glm") 

logis_fit_bmi <- logis_mdl_bmi |> 
    fit(GENDER ~ BMI, 
        data = df_trn, 
        family = "binomial")

predict(logis_fit_bmi$fit, newdata = data.frame(BMI = 165), type = "response")

```


4. Do the classification on the test set for the model (2) and (3), and compute the test accuracy rate. Which model gives us higher accuracy rate?

```{r}

# code
# height
pred_ht <- 
    pull(predict(logis_fit_ht, df_tst))
## Test accuracy rate
mean(pred_ht == df_tst$GENDER)
# bmi
pred_bmi <- 
    pull(predict(logis_fit_bmi, df_tst))
## Test accuracy rate
mean(pred_bmi == df_tst$BMI)

```
The better test accuracy rate is from the regression fitted to HEIGHT. It is around 85% while the test accuracy rate is 0% for BMI

5. Use **Python** to split the `body` data into a training set and a test set.

```{python}

## code
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
body = pd.read_csv('./data/body.csv')
body['GENDER'] = body['GENDER'].astype('category')
X = body[['HEIGHT']]
Y = body[['GENDER']]
X
Y
X_trn, X_tst, y_trn, y_tst = train_test_split(X, Y, test_size=0.2, random_state=6220587)
X_trn
y_trn

```


6. Use **Python** to fit a logistic regression with the predictor `BMI` using the training sample data. Find the probability that the subject is male given `BMI = 25`.

```{python}

# code
from sklearn.linear_model import LogisticRegression
x = np.array(X_trn['HEIGHT']).reshape(-1, 1) ## 2d array with one column
x
y = np.array(y_trn['GENDER']) ## 1d array
y
clf = LogisticRegression().fit(x, y)
new_data = pd.DataFrame({'BMI': [25]})
prob_male = clf.predict(new_data)
print(prob_male)

```


7. Use **Python** to do the classification on the test set. Compute the test accuracy rate.

```{python}

# code
y_pred = clf.predict(X_tst)
from sklearn.metrics import confusion_matrix
confusion_matrix(y_tst, y_pred)
y_tst_arr = np.array(y_tst['GENDER'])
#y_tst = y_tst[:, 1]
y_tst_arr
y_pred
np.mean(y_tst_arr == y_pred)

```


## K-Nearest Neighbors (KNN)

1. Fit the KNN with $K=1$ and $10$ using `BMI` on the training data and do the classification on the same test set used in logistic regression. Obtain the confusion matrix for each $K$. Which $K$ performs better? Why?

```{r}

# code
(knn_recipe <- recipes::recipe(GENDER ~ HEIGHT, data = df_trn) |> 
    step_normalize(all_predictors()))
(knn_mdl1 <- parsnip::nearest_neighbor(neighbors = 1) |> 
    set_mode("classification") |> 
    set_engine("kknn"))
(knn_mdl10 <- parsnip::nearest_neighbor(neighbors = 10) |> 
    set_mode("classification") |> 
    set_engine("kknn"))

(knn_fit1 <- workflows::workflow() |> 
    add_recipe(knn_recipe) |> 
    add_model(knn_mdl1) |> 
    fit(data = df_trn))
(knn_fit10 <- workflows::workflow() |> 
    add_recipe(knn_recipe) |> 
    add_model(knn_mdl10) |> 
    fit(data = df_trn))

knn_pred1 <- 
    pull(predict(knn_fit1, df_tst))

## Confusion matrix
table(knn_pred1, df_tst$GENDER)
## Test accuracy rate
mean(knn_pred1 == df_tst$GENDER)

knn_pred10 <- 
    pull(predict(knn_fit10, df_tst))

## Confusion matrix
table(knn_pred10, df_tst$GENDER)
## Test accuracy rate
mean(knn_pred10 == df_tst$GENDER)

```
The test accuracy rate is better for k=1 than k=10, meaning that k=1 performs better because a higher percentage of correct predictions were made with k=1


